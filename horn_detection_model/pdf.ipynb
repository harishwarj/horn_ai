{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2802-2803: truncated \\UXXXXXXXX escape (2359042901.py, line 293)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 293\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2802-2803: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'HornAI: Real-Time Vehicle Detection and Horn Intensity Control', 0, 1, 'C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, chapter_title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, chapter_title, 0, 1, 'L')\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "\n",
    "pdf.add_page()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "# Title page\n",
    "pdf.set_font('Arial', 'B', 16)\n",
    "pdf.cell(0, 10, 'HornAI: Real-Time Vehicle Detection and Horn Intensity Control', 0, 1, 'C')\n",
    "pdf.ln(10)\n",
    "pdf.set_font('Arial', '', 14)\n",
    "pdf.cell(0, 10, 'MINI PROJECT REPORT', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'Submitted in partial fulfillment of the requirements', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'for the award of the degree in', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'BACHELOR OF TECHNOLOGY', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'IN', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'COMPUTER SCIENCE AND ENGINEERING', 0, 1, 'C')\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, 'BY', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'HARISHWAR . C', 0, 1, 'C')\n",
    "pdf.ln(20)\n",
    "pdf.cell(0, 10, 'DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'APRIL 2024', 0, 1, 'C')\n",
    "pdf.add_page()\n",
    "\n",
    "# Bonafide certificate\n",
    "pdf.chapter_title('BONAFIDE CERTIFICATE')\n",
    "bonafide_text = \"\"\"This is to certify that this Project Report is the bonafide work of Mr. HARISHWAR.C who carried out the mini-project entitled HornAI: Real-Time Vehicle Detection and Horn Intensity Control, under our supervision from January 2023 to May 2023.\n",
    "\n",
    "Mini Project Coordinator 1\n",
    "Mrs. S. Nalini Poornima\n",
    "Assistant Professor\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "Mini Project Coordinator 2\n",
    "Dr. Usha\n",
    "Assistant Professor\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "HOD\n",
    "Dr. S. Geetha\n",
    "HOD of CSE\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "Submitted for Viva Voce Examination held on\n",
    "\n",
    "Internal Examiner: _______________________\n",
    "External Examiner: _______________________\n",
    "\"\"\"\n",
    "pdf.chapter_body(bonafide_text)\n",
    "\n",
    "# Declaration\n",
    "pdf.chapter_title('DECLARATION')\n",
    "declaration_text = \"\"\"I am Mr. HARISHWAR.C, hereby declare that the Mini Project Report entitled “HornAI: Real-Time Vehicle Detection and Horn Intensity Control” is done by me under the guidance of “Mrs. Nalini Poornima & Dr. Usha” and is submitted in partial fulfilment of the requirements for the award of the degree in Bachelor of Technology in Computer Science and Engineering.\n",
    "\n",
    "Date:\n",
    "Place: CHENNAI\n",
    "\n",
    "Signature of the Candidate: _______________________\n",
    "\"\"\"\n",
    "pdf.chapter_body(declaration_text)\n",
    "\n",
    "# Acknowledgement\n",
    "pdf.chapter_title('ACKNOWLEDGEMENT')\n",
    "acknowledgement_text = \"\"\"I would first like to thank our beloved Chancellor Thiru A.C. SHANMUGAM, B.A., B.L. and President Er. A.C.S. Arunkumar, B.Tech., M.B.A., for all the encouragement and support extended to me during the tenure of this project and also during my years of studies in this wonderful University.\n",
    "\n",
    "I express my heartfelt thanks to our Vice Chancellor Prof. Dr. S. Geethalakshmi for providing all the support for my Mini Project.\n",
    "\n",
    "I express my heartfelt thanks to our Head of the department, Prof. Dr. S. Geetha, who has been actively involved and very influential from the start till the completion of my project.\n",
    "\n",
    "My sincere thanks to my Project Coordinators Mrs. Chinchu Nair & Dr. Manikandan, for their continuous guidance and encouragement throughout this work, which has made the mini project a success.\n",
    "\n",
    "I would also like to thank all the teaching and non-teaching staff of the Computer Science and Engineering department for their constant support and encouragement given to me while achieving my project goals.\n",
    "\"\"\"\n",
    "pdf.chapter_body(acknowledgement_text)\n",
    "\n",
    "# Table of contents\n",
    "pdf.chapter_title('TABLE OF CONTENTS')\n",
    "contents = \"\"\"| CHAPTER | TITLE | PAGE NO |\n",
    "| ------- | ----- | ------- |\n",
    "| 1 | ABSTRACT | 1 |\n",
    "| 2 | INTRODUCTION | 2 |\n",
    "| 3 | PROBLEM DEFINITION | 3 |\n",
    "| 4 | OBJECTIVE OF THE PROJECT | 4 |\n",
    "| 5 | LITERATURE SURVEY | 5 |\n",
    "| 6 | REQUIREMENT ANALYSIS | 6 |\n",
    "| 7 | DESIGN | 7 |\n",
    "| 8 | IMPLEMENTATION | 9 |\n",
    "| 9 | SAMPLE CODE AND OUTPUT | 11 |\n",
    "| 10 | CONCLUSION | 25 |\n",
    "| 11 | REFERENCES/BIBLIOGRAPHY | 26 |\n",
    "\"\"\"\n",
    "pdf.chapter_body(contents)\n",
    "\n",
    "# Chapter 1 - Abstract\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 1 - ABSTRACT')\n",
    "abstract_text = \"\"\"HornAI is a real-time vehicle detection and horn intensity control system designed to enhance urban driving experiences by automatically adjusting the horn sound based on vehicle proximity. Leveraging the YOLOv8 model for vehicle detection and OpenCV for video processing, HornAI dynamically controls horn intensity to minimize noise pollution and ensure safe driving practices.\n",
    "\"\"\"\n",
    "pdf.chapter_body(abstract_text)\n",
    "\n",
    "# Chapter 2 - Introduction\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 2 - INTRODUCTION')\n",
    "introduction_text = \"\"\"In urban environments, excessive horn use contributes significantly to noise pollution. HornAI aims to address this issue by introducing a smart system that detects nearby vehicles and adjusts the horn intensity accordingly. By integrating advanced object detection techniques and real-time video processing, HornAI offers a practical solution for modern vehicles, ensuring safer and quieter streets.\n",
    "\"\"\"\n",
    "pdf.chapter_body(introduction_text)\n",
    "\n",
    "# Chapter 3 - Problem Definition\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 3 - PROBLEM DEFINITION')\n",
    "problem_definition_text = \"\"\"HornAI addresses the challenge of excessive noise pollution caused by vehicle horns in urban areas. Traditional vehicle horns do not adapt to the surrounding environment, leading to unnecessary loud noises even when not required. This project aims to develop a system that intelligently detects vehicle proximity and adjusts horn intensity, thus reducing noise pollution and enhancing road safety.\n",
    "\"\"\"\n",
    "pdf.chapter_body(problem_definition_text)\n",
    "\n",
    "# Chapter 4 - Objective of the Project\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 4 - OBJECTIVE OF THE PROJECT')\n",
    "objective_text = \"\"\"The primary objective of HornAI is to create a real-time vehicle detection system that dynamically controls the horn intensity based on the proximity of nearby vehicles. The system should:\n",
    "\n",
    "1. Detect vehicles accurately using the YOLOv8 model.\n",
    "2. Calculate the proximity of detected vehicles.\n",
    "3. Adjust horn intensity based on proximity.\n",
    "4. Provide a visual representation of the horn intensity.\n",
    "\"\"\"\n",
    "pdf.chapter_body(objective_text)\n",
    "\n",
    "# Chapter 5 - Literature Survey\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 5 - LITERATURE SURVEY')\n",
    "literature_survey_text = \"\"\"1. \"YOLOv8: A Comprehensive Review of Real-Time Object Detection Algorithms\" - Highlights advancements in object detection algorithms and the evolution of the YOLO series, emphasizing the efficiency and accuracy improvements in YOLOv8.\n",
    "2. \"Reducing Urban Noise Pollution with Smart Technologies\" - Discusses various smart technologies aimed at reducing urban noise pollution, providing context for the importance of adaptive horn systems.\n",
    "\"\"\"\n",
    "pdf.chapter_body(literature_survey_text)\n",
    "\n",
    "# Chapter 6 - Requirement Analysis\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 6 - REQUIREMENT ANALYSIS')\n",
    "requirement_analysis_text = \"\"\"EXISTING SYSTEMS\n",
    "\n",
    "- Traditional vehicle horns\n",
    "- Smart horn systems (limited adoption)\n",
    "\n",
    "PROPOSED SYSTEM\n",
    "\n",
    "HornAI features an intelligent system that uses the YOLOv8 model for real-time vehicle detection and adjusts horn intensity based on proximity. The system utilizes OpenCV for video processing and TensorFlow/Keras for model loading and inference.\n",
    "\n",
    "SOFTWARE/HARDWARE REQUIREMENTS\n",
    "\n",
    "- Languages: Python\n",
    "- Libraries: OpenCV, TensorFlow/Keras, Ultralytics YOLO\n",
    "- Hardware: Local system with webcam or video input, Processor: Intel Core i5 or higher, RAM: 8GB or higher\n",
    "\"\"\"\n",
    "pdf.chapter_body(requirement_analysis_text)\n",
    "\n",
    "# Chapter 7 - Design\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 7 - DESIGN')\n",
    "design_text = \"\"\"UML DIAGRAM\n",
    "\n",
    "- Use Case Diagram\n",
    "- Sequence Diagram\n",
    "- Class Diagram\n",
    "\n",
    "ARCHITECTURE DIAGRAM\n",
    "\n",
    "- System Architecture illustrating the interaction between the video input, detection module, proximity calculation, and horn intensity adjustment.\n",
    "\"\"\"\n",
    "pdf.chapter_body(design_text)\n",
    "\n",
    "# Chapter 8 - Implementation\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 8 - IMPLEMENTATION')\n",
    "implementation_text = \"\"\"MODULES DESCRIPTION\n",
    "\n",
    "1. User Interface Module: Provides the user interface for interacting with HornAI. It includes components for inputting video streams and displaying the processed frames with vehicle detection and horn intensity control.\n",
    "2. Input Processing Module: Processes video input before passing it to the detection module. This module handles tasks such as frame extraction and preprocessing.\n",
    "3. Detection Module: Uses YOLOv8 to detect vehicles in each frame. This module involves loading the YOLOv8 model and performing inference on the video frames.\n",
    "4. Proximity Calculation Module: Calculates the distance of detected vehicles from the camera based on the bounding box coordinates.\n",
    "5. Horn Control Module: Adjusts horn intensity based on the calculated proximity. This module determines the appropriate horn intensity level and updates the display accordingly.\n",
    "6. Display Module: Shows the video frames with detection boxes and the horn intensity bar. This module involves rendering the processed frames and overlaying detection information and the intensity bar.\n",
    "\"\"\"\n",
    "pdf.chapter_body(implementation_text)\n",
    "\n",
    "# Chapter 9 - Sample Code and Output\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 9 - SAMPLE CODE AND OUTPUT')\n",
    "sample_code_text = \"\"\"import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def preprocess_image(frame):\n",
    "    image = cv2.resize(frame, (640, 640))  # YOLOv8 uses 640x640 by default\n",
    "    image = image / 255.0\n",
    "    image is np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def calculate_proximity(x, y, w, h):\n",
    "    center_x, center_y = x + w / 2, y + h / 2\n",
    "    image_center_x, image_center_y = 640 / 2, 640 / 2\n",
    "    distance = ((center_x - image_center_x) ** 2 + (center_y - image_center_y) ** 2) ** 0.5\n",
    "    proximity is max(0, 1 - distance / (640 / 2))\n",
    "    return proximity * 100\n",
    "\n",
    "def display_frequency_bar(frame, intensity):\n",
    "    print(f\"Displaying frequency bar with intensity: {intensity:.2f}%\")  # Debugging statement\n",
    "    height, width, _ = frame.shape\n",
    "    bar_width = int(width * (intensity / 100))\n",
    "\n",
    "    # Create gradient color for the bar\n",
    "    bar_color is (0, 255, 0)  # Green\n",
    "    if intensity > 50:\n",
    "        bar_color = (0, 255, 255)  # Yellow\n",
    "    if intensity > 75:\n",
    "        bar_color = (0, 0, 255)  # Red\n",
    "\n",
    "    # Draw the bar background\n",
    "    cv2.rectangle(frame, (0, height - 50), (width, height), (50, 50, 50), -1)\n",
    "    \n",
    "    # Draw the filled intensity bar\n",
    "    cv2.rectangle(frame, (0, height - 50), (bar_width, height), bar_color, -1)\n",
    "    \n",
    "    # Draw text background\n",
    "    text is f'Horn Intensity: {intensity:.2f}%'\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "    text_background_x is 10\n",
    "    text_background_y is height - 60\n",
    "    cv2.rectangle(frame, (text_background_x - 5, text_background_y - text_height - 5), \n",
    "                  (text_background_x + text_width + 5, text_background_y + 5), (50, 50, 50), -1)\n",
    "    \n",
    "    # Draw the text on top of the bar\n",
    "    cv2.putText(frame, text, (10, height - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "def detect_and_control(frame, model):\n",
    "    results is model(frame)  # No need to preprocess here as the model handles it\n",
    "    intensity is 0\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, detection.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            proximity is calculate_proximity(x1, y1, w, h)\n",
    "            intensity is max(intensity, proximity)\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # Draw label\n",
    "            cls is int(detection.cls)  # Convert tensor to int\n",
    "            conf is float(detection.conf)  # Convert tensor to float\n",
    "            label is f'{cls}: {conf:.2f}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    display_frequency_bar(frame, intensity)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model is YOLO('yolov8n.pt')  # Replace with the path to your YOLOv8 model file\n",
    "\n",
    "# Capture video from file\n",
    "video_path is r\"C:\\Users\\Harishwar\\Desktop\\mini\\full_video\\Honda Odyssey 2012_silver.mp4\"  # Your video file path\n",
    "cap is cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detect_and_control(frame, model)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "pdf.chapter_body(sample_code_text)\n",
    "\n",
    "# Chapter 10 - Conclusion\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 10 - CONCLUSION')\n",
    "conclusion_text = \"\"\"In conclusion, HornAI presents a viable solution to mitigate noise pollution caused by vehicle horns in urban environments. By intelligently adjusting horn intensity based on vehicle proximity, the system ensures a quieter and safer driving experience. The integration of advanced object detection algorithms and real-time processing capabilities highlights the potential of AI in enhancing urban mobility and reducing environmental noise.\n",
    "\"\"\"\n",
    "pdf.chapter_body(conclusion_text)\n",
    "\n",
    "# Chapter 11 - References/Bibliography\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 11 - REFERENCES/BIBLIOGRAPHY')\n",
    "references_text = \"\"\"1. \"YOLOv8: A Comprehensive Review of Real-Time Object Detection Algorithms\" - Provides insights into the YOLOv8 model and its advancements.\n",
    "2. \"Reducing Urban Noise Pollution with Smart Technologies\" - Discusses the impact of smart technologies on urban noise reduction.\n",
    "3. Ultralytics YOLO GitHub Repository: https://github.com/ultralytics/yolov8\n",
    "4. OpenCV Documentation: https://docs.opencv.org\n",
    "\"\"\"\n",
    "pdf.chapter_body(references_text)\n",
    "\n",
    "# Save the PDF\n",
    "pdf_output_path = \"/mnt/data/HornAI_Project_Report.pdf\"\n",
    "pdf.output(pdf_output_path)\n",
    "\n",
    "pdf_output_path &#8203;:citation[【oaicite:0】]&#8203;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u201c' in position 480: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 315\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Save the PDF\u001b[39;00m\n\u001b[0;32m    314\u001b[0m pdf_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/HornAI_Project_Report.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 315\u001b[0m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_output_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m pdf_output_path\n",
      "File \u001b[1;32mc:\\Users\\Harishwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fpdf\\fpdf.py:1065\u001b[0m, in \u001b[0;36mFPDF.output\u001b[1;34m(self, name, dest)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m#Finish document if necessary\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m-> 1065\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1066\u001b[0m dest\u001b[38;5;241m=\u001b[39mdest\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dest\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Harishwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fpdf\\fpdf.py:246\u001b[0m, in \u001b[0;36mFPDF.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpage()\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m#close document\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enddoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Harishwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fpdf\\fpdf.py:1636\u001b[0m, in \u001b[0;36mFPDF._enddoc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_enddoc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putheader()\n\u001b[1;32m-> 1636\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_putpages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_putresources()\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;66;03m#Info\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Harishwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fpdf\\fpdf.py:1170\u001b[0m, in \u001b[0;36mFPDF._putpages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#Page content\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress:\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# manage binary data as latin1 until PEP461 or similar is implemented\u001b[39;00m\n\u001b[1;32m-> 1170\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m PY3K \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages[n] \n\u001b[0;32m   1171\u001b[0m     p \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcompress(p)\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u201c' in position 480: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'HornAI: Real-Time Vehicle Detection and Horn Intensity Control', 0, 1, 'C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, chapter_title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, chapter_title, 0, 1, 'L')\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "\n",
    "pdf.add_page()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "# Title page\n",
    "pdf.set_font('Arial', 'B', 16)\n",
    "pdf.cell(0, 10, 'HornAI: Real-Time Vehicle Detection and Horn Intensity Control', 0, 1, 'C')\n",
    "pdf.ln(10)\n",
    "pdf.set_font('Arial', '', 14)\n",
    "pdf.cell(0, 10, 'MINI PROJECT REPORT', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'Submitted in partial fulfillment of the requirements', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'for the award of the degree in', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'BACHELOR OF TECHNOLOGY', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'IN', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'COMPUTER SCIENCE AND ENGINEERING', 0, 1, 'C')\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, 'BY', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'HARISHWAR . C', 0, 1, 'C')\n",
    "pdf.ln(20)\n",
    "pdf.cell(0, 10, 'DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING', 0, 1, 'C')\n",
    "pdf.cell(0, 10, 'APRIL 2024', 0, 1, 'C')\n",
    "pdf.add_page()\n",
    "\n",
    "# Bonafide certificate\n",
    "pdf.chapter_title('BONAFIDE CERTIFICATE')\n",
    "bonafide_text = \"\"\"This is to certify that this Project Report is the bonafide work of Mr. HARISHWAR.C who carried out the mini-project entitled HornAI: Real-Time Vehicle Detection and Horn Intensity Control, under our supervision from January 2023 to May 2023.\n",
    "\n",
    "Mini Project Coordinator 1\n",
    "Mrs. S. Nalini Poornima\n",
    "Assistant Professor\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "Mini Project Coordinator 2\n",
    "Dr. Usha\n",
    "Assistant Professor\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "HOD\n",
    "Dr. S. Geetha\n",
    "HOD of CSE\n",
    "Dr. MGR Educational and Research Institute\n",
    "Deemed to be University\n",
    "\n",
    "Submitted for Viva Voce Examination held on\n",
    "\n",
    "Internal Examiner: _______________________\n",
    "External Examiner: _______________________\n",
    "\"\"\"\n",
    "pdf.chapter_body(bonafide_text)\n",
    "\n",
    "# Declaration\n",
    "pdf.chapter_title('DECLARATION')\n",
    "declaration_text = \"\"\"I am Mr. HARISHWAR.C, hereby declare that the Mini Project Report entitled “HornAI: Real-Time Vehicle Detection and Horn Intensity Control” is done by me under the guidance of “Mrs. Nalini Poornima & Dr. Usha” and is submitted in partial fulfilment of the requirements for the award of the degree in Bachelor of Technology in Computer Science and Engineering.\n",
    "\n",
    "Date:\n",
    "Place: CHENNAI\n",
    "\n",
    "Signature of the Candidate: _______________________\n",
    "\"\"\"\n",
    "pdf.chapter_body(declaration_text)\n",
    "\n",
    "# Acknowledgement\n",
    "pdf.chapter_title('ACKNOWLEDGEMENT')\n",
    "acknowledgement_text = \"\"\"I would first like to thank our beloved Chancellor Thiru A.C. SHANMUGAM, B.A., B.L. and President Er. A.C.S. Arunkumar, B.Tech., M.B.A., for all the encouragement and support extended to me during the tenure of this project and also during my years of studies in this wonderful University.\n",
    "\n",
    "I express my heartfelt thanks to our Vice Chancellor Prof. Dr. S. Geethalakshmi for providing all the support for my Mini Project.\n",
    "\n",
    "I express my heartfelt thanks to our Head of the department, Prof. Dr. S. Geetha, who has been actively involved and very influential from the start till the completion of my project.\n",
    "\n",
    "My sincere thanks to my Project Coordinators Mrs. Chinchu Nair & Dr. Manikandan, for their continuous guidance and encouragement throughout this work, which has made the mini project a success.\n",
    "\n",
    "I would also like to thank all the teaching and non-teaching staff of the Computer Science and Engineering department for their constant support and encouragement given to me while achieving my project goals.\n",
    "\"\"\"\n",
    "pdf.chapter_body(acknowledgement_text)\n",
    "\n",
    "# Table of contents\n",
    "pdf.chapter_title('TABLE OF CONTENTS')\n",
    "contents = \"\"\"| CHAPTER | TITLE | PAGE NO |\n",
    "| ------- | ----- | ------- |\n",
    "| 1 | ABSTRACT | 1 |\n",
    "| 2 | INTRODUCTION | 2 |\n",
    "| 3 | PROBLEM DEFINITION | 3 |\n",
    "| 4 | OBJECTIVE OF THE PROJECT | 4 |\n",
    "| 5 | LITERATURE SURVEY | 5 |\n",
    "| 6 | REQUIREMENT ANALYSIS | 6 |\n",
    "| 7 | DESIGN | 7 |\n",
    "| 8 | IMPLEMENTATION | 9 |\n",
    "| 9 | SAMPLE CODE AND OUTPUT | 11 |\n",
    "| 10 | CONCLUSION | 25 |\n",
    "| 11 | REFERENCES/BIBLIOGRAPHY | 26 |\n",
    "\"\"\"\n",
    "pdf.chapter_body(contents)\n",
    "\n",
    "# Chapter 1 - Abstract\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 1 - ABSTRACT')\n",
    "abstract_text = \"\"\"HornAI is a real-time vehicle detection and horn intensity control system designed to enhance urban driving experiences by automatically adjusting the horn sound based on vehicle proximity. Leveraging the YOLOv8 model for vehicle detection and OpenCV for video processing, HornAI dynamically controls horn intensity to minimize noise pollution and ensure safe driving practices.\n",
    "\"\"\"\n",
    "pdf.chapter_body(abstract_text)\n",
    "\n",
    "# Chapter 2 - Introduction\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 2 - INTRODUCTION')\n",
    "introduction_text = \"\"\"In urban environments, excessive horn use contributes significantly to noise pollution. HornAI aims to address this issue by introducing a smart system that detects nearby vehicles and adjusts the horn intensity accordingly. By integrating advanced object detection techniques and real-time video processing, HornAI offers a practical solution for modern vehicles, ensuring safer and quieter streets.\n",
    "\"\"\"\n",
    "pdf.chapter_body(introduction_text)\n",
    "\n",
    "# Chapter 3 - Problem Definition\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 3 - PROBLEM DEFINITION')\n",
    "problem_definition_text = \"\"\"HornAI addresses the challenge of excessive noise pollution caused by vehicle horns in urban areas. Traditional vehicle horns do not adapt to the surrounding environment, leading to unnecessary loud noises even when not required. This project aims to develop a system that intelligently detects vehicle proximity and adjusts horn intensity, thus reducing noise pollution and enhancing road safety.\n",
    "\"\"\"\n",
    "pdf.chapter_body(problem_definition_text)\n",
    "\n",
    "# Chapter 4 - Objective of the Project\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 4 - OBJECTIVE OF THE PROJECT')\n",
    "objective_text = \"\"\"The primary objective of HornAI is to create a real-time vehicle detection system that dynamically controls the horn intensity based on the proximity of nearby vehicles. The system should:\n",
    "\n",
    "1. Detect vehicles accurately using the YOLOv8 model.\n",
    "2. Calculate the proximity of detected vehicles.\n",
    "3. Adjust horn intensity based on proximity.\n",
    "4. Provide a visual representation of the horn intensity.\n",
    "\"\"\"\n",
    "pdf.chapter_body(objective_text)\n",
    "\n",
    "# Chapter 5 - Literature Survey\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 5 - LITERATURE SURVEY')\n",
    "literature_survey_text = \"\"\"1. \"YOLOv8: A Comprehensive Review of Real-Time Object Detection Algorithms\" - Highlights advancements in object detection algorithms and the evolution of the YOLO series, emphasizing the efficiency and accuracy improvements in YOLOv8.\n",
    "2. \"Reducing Urban Noise Pollution with Smart Technologies\" - Discusses various smart technologies aimed at reducing urban noise pollution, providing context for the importance of adaptive horn systems.\n",
    "\"\"\"\n",
    "pdf.chapter_body(literature_survey_text)\n",
    "\n",
    "# Chapter 6 - Requirement Analysis\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 6 - REQUIREMENT ANALYSIS')\n",
    "requirement_analysis_text = \"\"\"EXISTING SYSTEMS\n",
    "\n",
    "- Traditional vehicle horns\n",
    "- Smart horn systems (limited adoption)\n",
    "\n",
    "PROPOSED SYSTEM\n",
    "\n",
    "HornAI features an intelligent system that uses the YOLOv8 model for real-time vehicle detection and adjusts horn intensity based on proximity. The system utilizes OpenCV for video processing and TensorFlow/Keras for model loading and inference.\n",
    "\n",
    "SOFTWARE/HARDWARE REQUIREMENTS\n",
    "\n",
    "- Languages: Python\n",
    "- Libraries: OpenCV, TensorFlow/Keras, Ultralytics YOLO\n",
    "- Hardware: Local system with webcam or video input, Processor: Intel Core i5 or higher, RAM: 8GB or higher\n",
    "\"\"\"\n",
    "pdf.chapter_body(requirement_analysis_text)\n",
    "\n",
    "# Chapter 7 - Design\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 7 - DESIGN')\n",
    "design_text = \"\"\"UML DIAGRAM\n",
    "\n",
    "- Use Case Diagram\n",
    "- Sequence Diagram\n",
    "- Class Diagram\n",
    "\n",
    "ARCHITECTURE DIAGRAM\n",
    "\n",
    "- System Architecture illustrating the interaction between the video input, detection module, proximity calculation, and horn intensity adjustment.\n",
    "\"\"\"\n",
    "pdf.chapter_body(design_text)\n",
    "\n",
    "# Chapter 8 - Implementation\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 8 - IMPLEMENTATION')\n",
    "implementation_text = \"\"\"MODULES DESCRIPTION\n",
    "\n",
    "1. User Interface Module: Provides the user interface for interacting with HornAI. It includes components for inputting video streams and displaying the processed frames with vehicle detection and horn intensity control.\n",
    "2. Input Processing Module: Processes video input before passing it to the detection module. This module handles tasks such as frame extraction and preprocessing.\n",
    "3. Detection Module: Uses YOLOv8 to detect vehicles in each frame. This module involves loading the YOLOv8 model and performing inference on the video frames.\n",
    "4. Proximity Calculation Module: Calculates the distance of detected vehicles from the camera based on the bounding box coordinates.\n",
    "5. Horn Control Module: Adjusts horn intensity based on the calculated proximity. This module determines the appropriate horn intensity level and updates the display accordingly.\n",
    "6. Display Module: Shows the video frames with detection boxes and the horn intensity bar. This module involves rendering the processed frames and overlaying detection information and the intensity bar.\n",
    "\"\"\"\n",
    "pdf.chapter_body(implementation_text)\n",
    "\n",
    "# Chapter 9 - Sample Code and Output\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 9 - SAMPLE CODE AND OUTPUT')\n",
    "sample_code_text = r\"\"\"import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def preprocess_image(frame):\n",
    "    image = cv2.resize(frame, (640, 640))  # YOLOv8 uses 640x640 by default\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def calculate_proximity(x, y, w, h):\n",
    "    center_x, center_y = x + w / 2, y + h / 2\n",
    "    image_center_x, image_center_y = 640 / 2, 640 / 2\n",
    "    distance = ((center_x - image_center_x) ** 2 + (center_y - image_center_y) ** 2) ** 0.5\n",
    "    proximity = max(0, 1 - distance / (640 / 2))\n",
    "    return proximity * 100\n",
    "\n",
    "def display_frequency_bar(frame, intensity):\n",
    "    print(f\"Displaying frequency bar with intensity: {intensity:.2f}%\")  # Debugging statement\n",
    "    height, width, _ = frame.shape\n",
    "    bar_width = int(width * (intensity / 100))\n",
    "\n",
    "    # Create gradient color for the bar\n",
    "    bar_color = (0, 255, 0)  # Green\n",
    "    if intensity > 50:\n",
    "        bar_color = (0, 255, 255)  # Yellow\n",
    "    if intensity > 75:\n",
    "        bar_color = (0, 0, 255)  # Red\n",
    "\n",
    "    # Draw the bar background\n",
    "    cv2.rectangle(frame, (0, height - 50), (width, height), (50, 50, 50), -1)\n",
    "    \n",
    "    # Draw the filled intensity bar\n",
    "    cv2.rectangle(frame, (0, height - 50), (bar_width, height), bar_color, -1)\n",
    "    \n",
    "    # Draw text background\n",
    "    text = f'Horn Intensity: {intensity:.2f}%'\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "    text_background_x = 10\n",
    "    text_background_y = height - 60\n",
    "    cv2.rectangle(frame, (text_background_x - 5, text_background_y - text_height - 5), \n",
    "                  (text_background_x + text_width + 5, text_background_y + 5), (50, 50, 50), -1)\n",
    "    \n",
    "    # Draw the text on top of the bar\n",
    "    cv2.putText(frame, text, (10, height - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "def detect_and_control(frame, model):\n",
    "    results = model(frame)  # No need to preprocess here as the model handles it\n",
    "    intensity = 0\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, detection.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            proximity = calculate_proximity(x1, y1, w, h)\n",
    "            intensity = max(intensity, proximity)\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # Draw label\n",
    "            cls = int(detection.cls)  # Convert tensor to int\n",
    "            conf = float(detection.conf)  # Convert tensor to float\n",
    "            label = f'{cls}: {conf:.2f}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    display_frequency_bar(frame, intensity)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Replace with the path to your YOLOv8 model file\n",
    "\n",
    "# Capture video from file\n",
    "video_path = r\"C:\\\\Users\\\\Harishwar\\\\Desktop\\\\mini\\\\full_video\\\\Honda Odyssey 2012_silver.mp4\"  # Your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detect_and_control(frame, model)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "pdf.chapter_body(sample_code_text)\n",
    "\n",
    "# Chapter 10 - Conclusion\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 10 - CONCLUSION')\n",
    "conclusion_text = \"\"\"In conclusion, HornAI presents a viable solution to mitigate noise pollution caused by vehicle horns in urban environments. By intelligently adjusting horn intensity based on vehicle proximity, the system ensures a quieter and safer driving experience. The integration of advanced object detection algorithms and real-time processing capabilities highlights the potential of AI in enhancing urban mobility and reducing environmental noise.\n",
    "\"\"\"\n",
    "pdf.chapter_body(conclusion_text)\n",
    "\n",
    "# Chapter 11 - References/Bibliography\n",
    "pdf.add_page()\n",
    "pdf.chapter_title('CHAPTER 11 - REFERENCES/BIBLIOGRAPHY')\n",
    "references_text = \"\"\"1. \"YOLOv8: A Comprehensive Review of Real-Time Object Detection Algorithms\" - Provides insights into the YOLOv8 model and its advancements.\n",
    "2. \"Reducing Urban Noise Pollution with Smart Technologies\" - Discusses the impact of smart technologies on urban noise reduction.\n",
    "3. Ultralytics YOLO GitHub Repository: https://github.com/ultralytics/yolov8\n",
    "4. OpenCV Documentation: https://docs.opencv.org\n",
    "\"\"\"\n",
    "pdf.chapter_body(references_text)\n",
    "\n",
    "# Save the PDF\n",
    "pdf_output_path = \"/mnt/data/HornAI_Project_Report.pdf\"\n",
    "pdf.output(pdf_output_path)\n",
    "\n",
    "pdf_output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
